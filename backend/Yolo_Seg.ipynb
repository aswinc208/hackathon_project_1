{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.6 ðŸš€ Python-3.11.5 torch-2.1.2+cpu CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "\n",
      "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
      "image 1/1 c:\\Users\\Rahul\\Desktop\\New folder\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 1 handbag, 129.0ms\n",
      "Speed: 2.2ms preprocess, 129.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns\\segment\\predict3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=segment mode=predict model=yolov8s-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Rahul\\Desktop\\New folder\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 60.0ms\n",
      "Speed: 1.9ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([ 0., 16.,  2.])\n",
      "conf: tensor([0.7271, 0.2907, 0.2846])\n",
      "data: tensor([[0.0000e+00, 3.1447e+02, 6.2508e+02, 1.2782e+03, 7.2712e-01, 0.0000e+00],\n",
      "        [5.5173e+01, 2.5002e+02, 6.4811e+02, 1.2663e+03, 2.9066e-01, 1.6000e+01],\n",
      "        [6.3323e+02, 7.1954e+02, 7.0105e+02, 7.8603e+02, 2.8456e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1280, 720)\n",
      "shape: torch.Size([3, 6])\n",
      "xywh: tensor([[ 312.5378,  796.3331,  625.0755,  963.7230],\n",
      "        [ 351.6406,  758.1470,  592.9349, 1016.2500],\n",
      "        [ 667.1415,  752.7864,   67.8247,   66.4945]])\n",
      "xywhn: tensor([[0.4341, 0.6221, 0.8682, 0.7529],\n",
      "        [0.4884, 0.5923, 0.8235, 0.7939],\n",
      "        [0.9266, 0.5881, 0.0942, 0.0519]])\n",
      "xyxy: tensor([[   0.0000,  314.4716,  625.0755, 1278.1946],\n",
      "        [  55.1731,  250.0220,  648.1080, 1266.2720],\n",
      "        [ 633.2291,  719.5391,  701.0538,  786.0336]])\n",
      "xyxyn: tensor([[0.0000, 0.2457, 0.8682, 0.9986],\n",
      "        [0.0766, 0.1953, 0.9002, 0.9893],\n",
      "        [0.8795, 0.5621, 0.9737, 0.6141]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "source = r\"C:\\Users\\Rahul\\Desktop\\New folder\\dog.jpeg\"\n",
    "results = model(source)  # list of Results objects\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([ 0., 16.,  2.])\n",
      "conf: tensor([0.7271, 0.2907, 0.2846])\n",
      "data: tensor([[0.0000e+00, 3.1447e+02, 6.2508e+02, 1.2782e+03, 7.2712e-01, 0.0000e+00],\n",
      "        [5.5173e+01, 2.5002e+02, 6.4811e+02, 1.2663e+03, 2.9066e-01, 1.6000e+01],\n",
      "        [6.3323e+02, 7.1954e+02, 7.0105e+02, 7.8603e+02, 2.8456e-01, 2.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1280, 720)\n",
      "shape: torch.Size([3, 6])\n",
      "xywh: tensor([[ 312.5378,  796.3331,  625.0755,  963.7230],\n",
      "        [ 351.6406,  758.1470,  592.9349, 1016.2500],\n",
      "        [ 667.1415,  752.7864,   67.8247,   66.4945]])\n",
      "xywhn: tensor([[0.4341, 0.6221, 0.8682, 0.7529],\n",
      "        [0.4884, 0.5923, 0.8235, 0.7939],\n",
      "        [0.9266, 0.5881, 0.0942, 0.0519]])\n",
      "xyxy: tensor([[   0.0000,  314.4716,  625.0755, 1278.1946],\n",
      "        [  55.1731,  250.0220,  648.1080, 1266.2720],\n",
      "        [ 633.2291,  719.5391,  701.0538,  786.0336]])\n",
      "xyxyn: tensor([[0.0000, 0.2457, 0.8682, 0.9986],\n",
      "        [0.0766, 0.1953, 0.9002, 0.9893],\n",
      "        [0.8795, 0.5621, 0.9737, 0.6141]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for r in results:\n",
    "    print(r.boxes)  # print the Boxes object containing the detection bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding boxes for 'person' class in result:\n",
      "tensor([[   0.0000,  314.4716,  625.0755, 1278.1946]])\n",
      "Bounding boxes for 'person' class in result:\n",
      "tensor([], size=(0, 4))\n",
      "Bounding boxes for 'person' class in result:\n",
      "tensor([], size=(0, 4))\n"
     ]
    }
   ],
   "source": [
    "for r in boxes:\n",
    "    # Get the class IDs tensor for this result\n",
    "    class_ids = r.cls\n",
    "\n",
    "    # Get the bounding boxes for this result\n",
    "    bounding_boxes = r.xyxy\n",
    "\n",
    "    # Filter indices where the class ID corresponds to \"person\"\n",
    "    person_indices = (class_ids == 0).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    # Extract bounding boxes for the \"person\" class\n",
    "    person_boxes = bounding_boxes[person_indices]\n",
    "\n",
    "    # Print or use the bounding boxes for further processing\n",
    "    print(\"Bounding boxes for 'person' class in result:\")\n",
    "    print(person_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
